{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb1244d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Setup complete\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pypinyin import pinyin, Style\n",
    "import difflib\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path(\"../data/sample_audio\")\n",
    "REFERENCE_FILE = Path(\"../data/reference_phrases.json\")\n",
    "\n",
    "# Load reference data\n",
    "with open(REFERENCE_FILE, 'r', encoding='utf-8') as f:\n",
    "    reference_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "517059b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinyin Conversion Tests:\n",
      "\n",
      "你好     → ni3 hao3        → nǐ hǎo\n",
      "妈妈     → ma1 ma1         → mā mā\n",
      "马      → ma3             → mǎ\n",
      "骂      → ma4             → mà\n"
     ]
    }
   ],
   "source": [
    "def text_to_pinyin(text, style=Style.TONE3):\n",
    "    \"\"\"\n",
    "    Convert Chinese text to pinyin\n",
    "    \n",
    "    Args:\n",
    "        text: Chinese characters\n",
    "        style: Pinyin style (TONE3 = numeric tones like 'ni3 hao3')\n",
    "    \n",
    "    Returns:\n",
    "        List of pinyin syllables\n",
    "    \"\"\"\n",
    "    result = pinyin(text, style=style, heteronym=False)\n",
    "    # Flatten the nested list\n",
    "    return [syllable[0] for syllable in result]\n",
    "\n",
    "def text_to_pinyin_display(text):\n",
    "    \"\"\"Get pinyin with tone marks for display\"\"\"\n",
    "    result = pinyin(text, style=Style.TONE)\n",
    "    return ' '.join([syllable[0] for syllable in result])\n",
    "\n",
    "# Test the functions\n",
    "test_phrases = [\"你好\", \"妈妈\", \"马\", \"骂\"]\n",
    "\n",
    "print(\"Pinyin Conversion Tests:\\n\")\n",
    "for phrase in test_phrases:\n",
    "    numeric = text_to_pinyin(phrase, Style.TONE3)\n",
    "    display = text_to_pinyin_display(phrase)\n",
    "    print(f\"{phrase:6} → {' '.join(numeric):15} → {display}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76c32a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme Decomposition:\n",
      "\n",
      "Pinyin   Initial  Final    Tone  \n",
      "-----------------------------------\n",
      "ni3      n        i        3     \n",
      "hao3     h        ao       3     \n",
      "ma1      m        a        1     \n",
      "ma3      m        a        3     \n",
      "ma4      m        a        4     \n",
      "zhi1     zh       i        1     \n",
      "chi1     ch       i        1     \n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Syllable:\n",
    "    \"\"\"Represents a Mandarin syllable with components\"\"\"\n",
    "    full: str           # Full pinyin (e.g., 'ni3')\n",
    "    initial: str        # Initial consonant (e.g., 'n')\n",
    "    final: str          # Final vowel/ending (e.g., 'i')\n",
    "    tone: str           # Tone number (e.g., '3')\n",
    "    \n",
    "def decompose_pinyin(pinyin_syllable):\n",
    "    \"\"\"\n",
    "    Break pinyin into initial, final, and tone\n",
    "    \n",
    "    Mandarin syllable structure: (Initial) + Final + Tone\n",
    "    Initial = optional consonant at start (b, p, m, f, d, t, n, l, etc.)\n",
    "    Final = vowel + optional nasal ending (a, o, e, i, u, ü, an, en, ang, eng, etc.)\n",
    "    Tone = 1, 2, 3, 4, or 5 (neutral)\n",
    "    \"\"\"\n",
    "    # Mandarin initials (consonants that can start a syllable)\n",
    "    initials = ['b', 'p', 'm', 'f', 'd', 't', 'n', 'l', 'g', 'k', 'h', \n",
    "                'j', 'q', 'x', 'zh', 'ch', 'sh', 'r', 'z', 'c', 's', 'y', 'w']\n",
    "    \n",
    "    # Extract tone (last character if it's a digit)\n",
    "    if pinyin_syllable and pinyin_syllable[-1].isdigit():\n",
    "        tone = pinyin_syllable[-1]\n",
    "        base = pinyin_syllable[:-1]\n",
    "    else:\n",
    "        tone = '5'  # Neutral tone\n",
    "        base = pinyin_syllable\n",
    "    \n",
    "    # Find initial (longest matching prefix)\n",
    "    initial = ''\n",
    "    final = base\n",
    "    \n",
    "    for init in sorted(initials, key=len, reverse=True):  # Check longest first\n",
    "        if base.startswith(init):\n",
    "            initial = init\n",
    "            final = base[len(init):]\n",
    "            break\n",
    "    \n",
    "    return Syllable(\n",
    "        full=pinyin_syllable,\n",
    "        initial=initial,\n",
    "        final=final,\n",
    "        tone=tone\n",
    "    )\n",
    "\n",
    "# Test decomposition\n",
    "test_syllables = ['ni3', 'hao3', 'ma1', 'ma3', 'ma4', 'zhi1', 'chi1']\n",
    "\n",
    "print(\"Phoneme Decomposition:\\n\")\n",
    "print(f\"{'Pinyin':<8} {'Initial':<8} {'Final':<8} {'Tone':<6}\")\n",
    "print(\"-\" * 35)\n",
    "for syl in test_syllables:\n",
    "    decomposed = decompose_pinyin(syl)\n",
    "    print(f\"{decomposed.full:<8} {decomposed.initial:<8} {decomposed.final:<8} {decomposed.tone:<6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c72cd281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Pronunciations:\n",
      "\n",
      "\n",
      "你好 (ni_hao)\n",
      "  Pinyin: ni3 hao3\n",
      "  Syllables: [n-i-3] [h-ao-3] \n",
      "\n",
      "你好 (ni_hao_incorrect)\n",
      "  Pinyin: ni3 hao3\n",
      "  Syllables: [n-i-3] [h-ao-3] \n",
      "\n",
      "谢谢 (xie_xie)\n",
      "  Pinyin: xie4 xie4\n",
      "  Syllables: [x-ie-4] [x-ie-4] \n",
      "\n",
      "妈妈 (ma_ma)\n",
      "  Pinyin: ma1 ma1\n",
      "  Syllables: [m-a-1] [m-a-1] \n",
      "\n",
      "马 (ma_horse)\n",
      "  Pinyin: ma3\n",
      "  Syllables: [m-a-3] \n",
      "\n",
      "骂 (ma_scold)\n",
      "  Pinyin: ma4\n",
      "  Syllables: [m-a-4] \n",
      "\n",
      "我在学中文 (wo_zai_xue_zhong_wen)\n",
      "  Pinyin: wo3 zai4 xue2 zhong1 wen2\n",
      "  Syllables: [w-o-3] [z-ai-4] [x-ue-2] [zh-ong-1] [w-en-2] \n",
      "\n",
      "今天天气很好 (jin_tian_tian_qi_hen_hao)\n",
      "  Pinyin: jin1 tian1 tian1 qi4 hen3 hao3\n",
      "  Syllables: [j-in-1] [t-ian-1] [t-ian-1] [q-i-4] [h-en-3] [h-ao-3] \n",
      "\n",
      "知道 (zhi_dao)\n",
      "  Pinyin: zhi1 dao4\n",
      "  Syllables: [zh-i-1] [d-ao-4] \n",
      "\n",
      "吃饭 (chi_fan)\n",
      "  Pinyin: chi1 fan4\n",
      "  Syllables: [ch-i-1] [f-an-4] \n"
     ]
    }
   ],
   "source": [
    "# We need to load the transcription results from Day 2\n",
    "# Let's recreate the comparison with pinyin added\n",
    "\n",
    "def load_and_analyze_transcriptions():\n",
    "    \"\"\"Load reference data and add pinyin analysis\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for phrase_data in reference_data['phrases']:\n",
    "        filename = phrase_data['filename']\n",
    "        expected_chinese = phrase_data['chinese']\n",
    "        expected_pinyin_str = phrase_data['pinyin']\n",
    "        \n",
    "        # Convert expected to pinyin syllables\n",
    "        expected_pinyin = text_to_pinyin(expected_chinese, Style.TONE3)\n",
    "        \n",
    "        results.append({\n",
    "            'filename': filename,\n",
    "            'expected_chinese': expected_chinese,\n",
    "            'expected_pinyin_str': expected_pinyin_str,\n",
    "            'expected_pinyin': expected_pinyin,\n",
    "            'expected_syllables': [decompose_pinyin(syl) for syl in expected_pinyin]\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "analysis_df = load_and_analyze_transcriptions()\n",
    "\n",
    "# Display sample\n",
    "print(\"Expected Pronunciations:\\n\")\n",
    "for idx, row in analysis_df.iterrows():\n",
    "    print(f\"\\n{row['expected_chinese']} ({row['filename']})\")\n",
    "    print(f\"  Pinyin: {' '.join(row['expected_pinyin'])}\")\n",
    "    print(f\"  Syllables: \", end='')\n",
    "    for syl in row['expected_syllables']:\n",
    "        print(f\"[{syl.initial}-{syl.final}-{syl.tone}] \", end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96ce2313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syllable Comparison Tests:\n",
      "\n",
      "ma1 vs ma1: ✓ Correct\n",
      "ma1 vs ma3: ✗ tone: first tone (flat) → third tone (fall-rise)\n",
      "ni3 vs li3: ✗ initial: 'n' → 'l'\n",
      "hao3 vs hao4: ✗ tone: third tone (fall-rise) → fourth tone (falling)\n"
     ]
    }
   ],
   "source": [
    "def compare_syllables(expected: Syllable, actual: Syllable) -> Dict:\n",
    "    \"\"\"\n",
    "    Compare two syllables and identify differences\n",
    "    \n",
    "    Returns dict with:\n",
    "        - match: bool (exact match)\n",
    "        - initial_match: bool\n",
    "        - final_match: bool  \n",
    "        - tone_match: bool\n",
    "        - feedback: str (description of error)\n",
    "    \"\"\"\n",
    "    if expected.full == actual.full:\n",
    "        return {\n",
    "            'match': True,\n",
    "            'initial_match': True,\n",
    "            'final_match': True,\n",
    "            'tone_match': True,\n",
    "            'feedback': '✓ Correct'\n",
    "        }\n",
    "    \n",
    "    initial_match = expected.initial == actual.initial\n",
    "    final_match = expected.final == actual.final\n",
    "    tone_match = expected.tone == actual.tone\n",
    "    \n",
    "    # Generate specific feedback\n",
    "    errors = []\n",
    "    if not initial_match:\n",
    "        errors.append(f\"initial: '{expected.initial}' → '{actual.initial}'\")\n",
    "    if not final_match:\n",
    "        errors.append(f\"final: '{expected.final}' → '{actual.final}'\")\n",
    "    if not tone_match:\n",
    "        tone_names = {\n",
    "            '1': 'first tone (flat)',\n",
    "            '2': 'second tone (rising)', \n",
    "            '3': 'third tone (fall-rise)',\n",
    "            '4': 'fourth tone (falling)',\n",
    "            '5': 'neutral tone'\n",
    "        }\n",
    "        errors.append(\n",
    "            f\"tone: {tone_names.get(expected.tone, expected.tone)} → \"\n",
    "            f\"{tone_names.get(actual.tone, actual.tone)}\"\n",
    "        )\n",
    "    \n",
    "    feedback = \"✗ \" + \", \".join(errors)\n",
    "    \n",
    "    return {\n",
    "        'match': False,\n",
    "        'initial_match': initial_match,\n",
    "        'final_match': final_match,\n",
    "        'tone_match': tone_match,\n",
    "        'feedback': feedback\n",
    "    }\n",
    "\n",
    "# Test comparison\n",
    "test_cases = [\n",
    "    (decompose_pinyin('ma1'), decompose_pinyin('ma1')),  # Perfect match\n",
    "    (decompose_pinyin('ma1'), decompose_pinyin('ma3')),  # Wrong tone\n",
    "    (decompose_pinyin('ni3'), decompose_pinyin('li3')),  # Wrong initial\n",
    "    (decompose_pinyin('hao3'), decompose_pinyin('hao4')), # Wrong tone\n",
    "]\n",
    "\n",
    "print(\"Syllable Comparison Tests:\\n\")\n",
    "for expected, actual in test_cases:\n",
    "    result = compare_syllables(expected, actual)\n",
    "    print(f\"{expected.full} vs {actual.full}: {result['feedback']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "790852fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Pronunciation Assessments:\n",
      "\n",
      "\n",
      "Expected: 你好 → Actual: 你好\n",
      "Score: 100.0%\n",
      "Expected pinyin: ni3 hao3\n",
      "Actual pinyin: ni3 hao3\n",
      "Summary: ✓ Perfect pronunciation!\n",
      "\n",
      "Expected: 妈妈 → Actual: 妈妈\n",
      "Score: 100.0%\n",
      "Expected pinyin: ma1 ma1\n",
      "Actual pinyin: ma1 ma1\n",
      "Summary: ✓ Perfect pronunciation!\n",
      "\n",
      "Expected: 马 → Actual: 妈妈\n",
      "Score: 0%\n",
      "Expected pinyin: ma3\n",
      "Actual pinyin: ma1 ma1\n",
      "Summary: Length mismatch: expected 1 syllables, got 2\n",
      "\n",
      "Expected: 骂 → Actual: 妈妈\n",
      "Score: 0%\n",
      "Expected pinyin: ma4\n",
      "Actual pinyin: ma1 ma1\n",
      "Summary: Length mismatch: expected 1 syllables, got 2\n"
     ]
    }
   ],
   "source": [
    "def assess_pronunciation(expected_chinese: str, actual_chinese: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Complete pronunciation assessment\n",
    "    \n",
    "    Args:\n",
    "        expected_chinese: What should have been said\n",
    "        actual_chinese: What was actually said (from Whisper)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with detailed assessment\n",
    "    \"\"\"\n",
    "    # Convert to pinyin\n",
    "    expected_pinyin = text_to_pinyin(expected_chinese, Style.TONE3)\n",
    "    actual_pinyin = text_to_pinyin(actual_chinese, Style.TONE3)\n",
    "    \n",
    "    # Decompose into syllables\n",
    "    expected_syllables = [decompose_pinyin(syl) for syl in expected_pinyin]\n",
    "    actual_syllables = [decompose_pinyin(syl) for syl in actual_pinyin]\n",
    "    \n",
    "    # Handle length mismatch\n",
    "    if len(expected_syllables) != len(actual_syllables):\n",
    "        return {\n",
    "            'overall_match': False,\n",
    "            'score': 0,\n",
    "            'expected_pinyin': ' '.join(expected_pinyin),\n",
    "            'actual_pinyin': ' '.join(actual_pinyin),\n",
    "            'syllable_details': [],\n",
    "            'summary': f\"Length mismatch: expected {len(expected_syllables)} syllables, \"\n",
    "                      f\"got {len(actual_syllables)}\"\n",
    "        }\n",
    "    \n",
    "    # Compare syllable by syllable\n",
    "    syllable_comparisons = []\n",
    "    for i, (exp_syl, act_syl) in enumerate(zip(expected_syllables, actual_syllables)):\n",
    "        comparison = compare_syllables(exp_syl, act_syl)\n",
    "        comparison['position'] = i\n",
    "        comparison['expected'] = exp_syl.full\n",
    "        comparison['actual'] = act_syl.full\n",
    "        syllable_comparisons.append(comparison)\n",
    "    \n",
    "    # Calculate overall score\n",
    "    total_components = len(expected_syllables) * 3  # initial + final + tone\n",
    "    correct_components = sum([\n",
    "        comp['initial_match'] + comp['final_match'] + comp['tone_match']\n",
    "        for comp in syllable_comparisons\n",
    "    ])\n",
    "    \n",
    "    score = (correct_components / total_components) * 100 if total_components > 0 else 0\n",
    "    overall_match = all(comp['match'] for comp in syllable_comparisons)\n",
    "    \n",
    "    return {\n",
    "        'overall_match': overall_match,\n",
    "        'score': round(score, 1),\n",
    "        'expected_pinyin': ' '.join(expected_pinyin),\n",
    "        'actual_pinyin': ' '.join(actual_pinyin),\n",
    "        'syllable_details': syllable_comparisons,\n",
    "        'summary': generate_feedback_summary(syllable_comparisons)\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_feedback_summary(comparisons: List[Dict]) -> str:\n",
    "    \"\"\"Generate human-readable feedback summary\"\"\"\n",
    "    if all(c['match'] for c in comparisons):\n",
    "        return \"✓ Perfect pronunciation!\"\n",
    "    \n",
    "    tone_errors = sum(1 for c in comparisons if not c['tone_match'])\n",
    "    initial_errors = sum(1 for c in comparisons if not c['initial_match'])\n",
    "    final_errors = sum(1 for c in comparisons if not c['final_match'])\n",
    "    \n",
    "    feedback_parts = []\n",
    "    if tone_errors > 0:\n",
    "        feedback_parts.append(f\"{tone_errors} tone error(s)\")\n",
    "    if initial_errors > 0:\n",
    "        feedback_parts.append(f\"{initial_errors} initial consonant error(s)\")\n",
    "    if final_errors > 0:\n",
    "        feedback_parts.append(f\"{final_errors} vowel/final error(s)\")\n",
    "    \n",
    "    return \"Issues: \" + \", \".join(feedback_parts)\n",
    "\n",
    "# Test the full assessment\n",
    "test_assessments = [\n",
    "    (\"你好\", \"你好\"),      # Perfect\n",
    "    (\"妈妈\", \"妈妈\"),      # Perfect  \n",
    "    (\"马\", \"妈妈\"),        # Wrong word\n",
    "    (\"骂\", \"妈妈\"),        # Wrong word\n",
    "]\n",
    "\n",
    "print(\"Full Pronunciation Assessments:\\n\")\n",
    "for expected, actual in test_assessments:\n",
    "    result = assess_pronunciation(expected, actual)\n",
    "    print(f\"\\nExpected: {expected} → Actual: {actual}\")\n",
    "    print(f\"Score: {result['score']}%\")\n",
    "    print(f\"Expected pinyin: {result['expected_pinyin']}\")\n",
    "    print(f\"Actual pinyin: {result['actual_pinyin']}\")\n",
    "    print(f\"Summary: {result['summary']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a384cd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Recording Assessments:\n",
      "\n",
      "================================================================================\n",
      "\n",
      "File: chi_fan.wav\n",
      "Expected: 吃饭 (chi1 fan4)\n",
      "Actual:   吃饭 (chi1 fan4)\n",
      "Score: 100.0% - ✓ Perfect pronunciation!\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "File: jin_tian_tian_qi_hen_hao.wav\n",
      "Expected: 今天天气很好 (jin1 tian1 tian1 qi4 hen3 hao3)\n",
      "Actual:   今天天气很好 (jin1 tian1 tian1 qi4 hen3 hao3)\n",
      "Score: 100.0% - ✓ Perfect pronunciation!\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "File: ma_horse.wav\n",
      "Expected: 马 (ma3)\n",
      "Actual:   马 (ma3)\n",
      "Score: 100.0% - ✓ Perfect pronunciation!\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "File: ma_ma.wav\n",
      "Expected: 妈妈 (ma1 ma1)\n",
      "Actual:   妈妈 (ma1 ma1)\n",
      "Score: 100.0% - ✓ Perfect pronunciation!\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "File: ma_scold.wav\n",
      "Expected: 骂 (ma4)\n",
      "Actual:   妈 (ma1)\n",
      "Score: 66.7% - Issues: 1 tone error(s)\n",
      "\n",
      "Detailed Feedback:\n",
      "  Syllable 1: ✗ tone: fourth tone (falling) → first tone (flat)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "File: ni_hao.wav\n",
      "Expected: 你好 (ni3 hao3)\n",
      "Actual:   你好 (ni3 hao3)\n",
      "Score: 100.0% - ✓ Perfect pronunciation!\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "File: ni_hao_incorrect.wav\n",
      "Expected: 你好 (ni3 hao3)\n",
      "Actual:   Ni Hao (Ni Hao)\n",
      "Score: 0% - Length mismatch: expected 2 syllables, got 1\n",
      "\n",
      "Detailed Feedback:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "File: wo_zai_xue_zhong_wen.wav\n",
      "Expected: 我在学中文 (wo3 zai4 xue2 zhong1 wen2)\n",
      "Actual:   我在学中文 (wo3 zai4 xue2 zhong1 wen2)\n",
      "Score: 100.0% - ✓ Perfect pronunciation!\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "File: xie_xie.wav\n",
      "Expected: 谢谢 (xie4 xie4)\n",
      "Actual:   谢谢 (xie4 xie4)\n",
      "Score: 100.0% - ✓ Perfect pronunciation!\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "File: zhi_dao.wav\n",
      "Expected: 知道 (zhi1 dao4)\n",
      "Actual:   知道 (zhi1 dao4)\n",
      "Score: 100.0% - ✓ Perfect pronunciation!\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "SUMMARY STATISTICS\n",
      "================================================================================\n",
      "Total recordings assessed: 10\n",
      "Perfect pronunciations: 8\n",
      "Average score: 86.7%\n",
      "Median score: 100.0%\n",
      "Score range: 0.0% - 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Load transcription results from previous notebook\n",
    "transcriptions_df = pd.read_csv(\"../data/transcriptions_df.csv\")\n",
    "\n",
    "# Load reference data for expected values\n",
    "reference_df = pd.DataFrame(reference_data['phrases'])\n",
    "\n",
    "# Merge to get expected Chinese characters\n",
    "merged_df = transcriptions_df.merge(\n",
    "    reference_df[['filename', 'chinese']],\n",
    "    left_on='base_filename',\n",
    "    right_on='filename',\n",
    "    how='left',\n",
    "    suffixes=('', '_ref')\n",
    ")\n",
    "\n",
    "# Rename for clarity\n",
    "merged_df = merged_df.rename(columns={\n",
    "    'chinese': 'expected',\n",
    "    'transcription': 'actual'\n",
    "})\n",
    "\n",
    "print(\"Real Recording Assessments:\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "assessment_results = []\n",
    "\n",
    "for idx, row in merged_df.iterrows():\n",
    "    # Skip if we don't have both expected and actual\n",
    "    if pd.isna(row['expected']) or pd.isna(row['actual']):\n",
    "        print(f\"\\nFile: {row['base_filename']}.wav - SKIPPED (missing data)\")\n",
    "        print(\"-\"*80)\n",
    "        continue\n",
    "    \n",
    "    result = assess_pronunciation(row['expected'], row['actual'])\n",
    "    \n",
    "    # Store for later analysis\n",
    "    assessment_results.append({\n",
    "        'filename': row['base_filename'],\n",
    "        'expected': row['expected'],\n",
    "        'actual': row['actual'],\n",
    "        'score': result['score'],\n",
    "        'overall_match': result['overall_match']\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nFile: {row['base_filename']}.wav\")\n",
    "    print(f\"Expected: {row['expected']} ({result['expected_pinyin']})\")\n",
    "    print(f\"Actual:   {row['actual']} ({result['actual_pinyin']})\")\n",
    "    print(f\"Score: {result['score']}% - {result['summary']}\")\n",
    "    \n",
    "    if not result['overall_match']:\n",
    "        print(\"\\nDetailed Feedback:\")\n",
    "        for detail in result['syllable_details']:\n",
    "            if not detail['match']:\n",
    "                print(f\"  Syllable {detail['position']+1}: {detail['feedback']}\")\n",
    "    \n",
    "    print(\"-\"*80)\n",
    "\n",
    "# Summary statistics\n",
    "assessment_df = pd.DataFrame(assessment_results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total recordings assessed: {len(assessment_df)}\")\n",
    "print(f\"Perfect pronunciations: {assessment_df['overall_match'].sum()}\")\n",
    "print(f\"Average score: {assessment_df['score'].mean():.1f}%\")\n",
    "print(f\"Median score: {assessment_df['score'].median():.1f}%\")\n",
    "print(f\"Score range: {assessment_df['score'].min():.1f}% - {assessment_df['score'].max():.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba2c8c1",
   "metadata": {},
   "source": [
    "## Two Issues:\n",
    "\n",
    "### 1. \"Ni Hao\" Romanization Problem\n",
    "\n",
    "This is a genuine limitation. When Whisper can't confidently match audio to Chinese phonemes, it falls back to romanization. This creates a UX problem:\n",
    "\n",
    "- **Root cause:** Whisper's confidence threshold. Poor pronunciation → low confidence → fallback to romanized output\n",
    "- **Why this matters:** Beginners (our target market) will hit this constantly. A system that returns \"Sorry, too unclear\" isn't helpful.\n",
    "\n",
    "**Possible solutions:**\n",
    "- (a) Force Chinese output mode (doesn't exist in Whisper API unfortunately)\n",
    "- (b) Fuzzy matching: If Whisper returns romanization, try to map \"Ni Hao\" → closest Chinese match from expected phrases\n",
    "- (c) Use a different model for very poor pronunciation: Models specifically trained on learner speech (not Whisper)\n",
    "- (d) Hybrid approach: If romanization detected, fall back to simpler \"try again\" feedback rather than detailed phoneme analysis\n",
    "\n",
    "### 2. 骂 vs 妈 Confusion\n",
    "\n",
    "This is likely **Whisper's language model bias**.\n",
    "\n",
    "**Language models have priors.** Whisper was trained on natural speech where:\n",
    "- 妈 (mother) appears 1000x more frequently than 骂 (scold)\n",
    "- People rarely say 骂 in isolation\n",
    "- Given ambiguous audio, the model defaults to the more common word\n",
    "\n",
    "**This is a fundamental challenge in speech recognition:** acoustic model says \"ma-ish sound with falling tone\" → language model says \"probably 妈 not 骂 because context\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
